{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T22:05:25.742679Z",
     "iopub.status.busy": "2025-04-17T22:05:25.742342Z",
     "iopub.status.idle": "2025-04-17T22:16:19.711174Z",
     "shell.execute_reply": "2025-04-17T22:16:19.710178Z",
     "shell.execute_reply.started": "2025-04-17T22:05:25.742657Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312f9129b57147dfaf2b3148b826561b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/533 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba04adfc3043407aa883f2a1b1574b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 22:05:56.206936: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744927556.664540      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744927556.794380      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "872920d1fa214a0fb3ecf61d43820687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959cf0f9139f433a96849375b89a1a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading stock price data...\n",
      "CSV structure sample:\n",
      "        Price  Adj Close                                                \\\n",
      "       Ticker       AAPL       AMZN      GOOGL        META        NFLX   \n",
      "0  2018-01-02  40.479839  59.450500  53.405170  180.568954  201.070007   \n",
      "1  2018-01-03  40.472782  60.209999  54.316319  183.803741  205.050003   \n",
      "2  2018-01-04  40.660774  60.479500  54.527306  183.465317  205.630005   \n",
      "\n",
      "       Close                                    ...       Open             \\\n",
      "        AAPL       AMZN      GOOGL        META  ...       AMZN      GOOGL   \n",
      "0  43.064999  59.450500  53.660500  181.419998  ...  58.599998  52.651001   \n",
      "1  43.057499  60.209999  54.576000  184.669998  ...  59.415001  53.696499   \n",
      "2  43.257500  60.479500  54.787998  184.330002  ...  60.250000  54.854500   \n",
      "\n",
      "                                Volume                                      \\\n",
      "         META        NFLX         AAPL        AMZN       GOOGL        META   \n",
      "0  177.679993  196.100006  102223600.0  53890000.0  31766000.0  18151900.0   \n",
      "1  181.880005  202.050003  118071600.0  62176000.0  31318000.0  16886600.0   \n",
      "2  184.899994  206.199997   89738400.0  60442000.0  26052000.0  13880900.0   \n",
      "\n",
      "                  is_business_day  \n",
      "         NFLX Unnamed: 31_level_1  \n",
      "0  10966900.0                True  \n",
      "1   8591400.0                True  \n",
      "2   6029600.0                True  \n",
      "\n",
      "[3 rows x 32 columns]\n",
      "CSV date range: 2018-01-02 → 2018-05-30\n",
      "Number of trading days: 149\n",
      "✅ All required stock columns are present.\n",
      "Model initialized with PCA reduction.\n",
      "\n",
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing train:   0%|          | 0/345 [00:00<?, ?it/s]\u001b[A\n",
      "Processing train:   0%|          | 1/345 [00:02<13:40,  2.39s/it]\u001b[A\n",
      "Processing train:   1%|          | 2/345 [00:03<09:17,  1.63s/it]\u001b[A\n",
      "Processing train:   1%|          | 3/345 [00:04<07:44,  1.36s/it]\u001b[A\n",
      "Processing train:   1%|          | 4/345 [00:05<07:01,  1.24s/it]\u001b[A\n",
      "Processing train:   1%|▏         | 5/345 [00:06<06:36,  1.16s/it]\u001b[A\n",
      "Processing train:   2%|▏         | 6/345 [00:07<06:58,  1.24s/it]\u001b[A\n",
      "Processing train:   2%|▏         | 7/345 [00:09<07:07,  1.26s/it]\u001b[A\n",
      "Processing train:   2%|▏         | 8/345 [00:10<06:44,  1.20s/it]\u001b[A\n",
      "Processing train:   3%|▎         | 9/345 [00:11<06:28,  1.16s/it]\u001b[A\n",
      "Processing train:   3%|▎         | 10/345 [00:12<06:18,  1.13s/it]\u001b[A\n",
      "Processing train:   3%|▎         | 11/345 [00:13<06:15,  1.13s/it]\u001b[A\n",
      "Processing train:   3%|▎         | 12/345 [00:14<06:16,  1.13s/it]\u001b[A\n",
      "Processing train:   4%|▍         | 13/345 [00:15<06:11,  1.12s/it]\u001b[A\n",
      "Processing train:   4%|▍         | 14/345 [00:16<06:06,  1.11s/it]\u001b[A\n",
      "Processing train:   4%|▍         | 15/345 [00:17<06:01,  1.10s/it]\u001b[A\n",
      "Processing train:   5%|▍         | 16/345 [00:19<06:01,  1.10s/it]\u001b[A\n",
      "Processing train:   5%|▍         | 17/345 [00:20<05:50,  1.07s/it]\u001b[A\n",
      "Processing train:   5%|▌         | 18/345 [00:21<05:46,  1.06s/it]\u001b[A\n",
      "Processing train:   6%|▌         | 19/345 [00:22<05:42,  1.05s/it]\u001b[A\n",
      "Processing train:   6%|▌         | 20/345 [00:23<05:39,  1.04s/it]\u001b[A\n",
      "Processing train:   6%|▌         | 21/345 [00:24<05:35,  1.04s/it]\u001b[A\n",
      "Processing train:   6%|▋         | 22/345 [00:25<05:37,  1.04s/it]\u001b[A\n",
      "Processing train:   7%|▋         | 23/345 [00:26<05:35,  1.04s/it]\u001b[A\n",
      "Processing train:   7%|▋         | 24/345 [00:27<05:34,  1.04s/it]\u001b[A\n",
      "Processing train:   7%|▋         | 25/345 [00:28<05:31,  1.04s/it]\u001b[A\n",
      "Processing train:   8%|▊         | 26/345 [00:29<05:31,  1.04s/it]\u001b[A\n",
      "Processing train:   8%|▊         | 27/345 [00:30<05:33,  1.05s/it]\u001b[A\n",
      "Processing train:   8%|▊         | 28/345 [00:31<05:35,  1.06s/it]\u001b[A\n",
      "Processing train:   8%|▊         | 29/345 [00:32<05:35,  1.06s/it]\u001b[A\n",
      "Processing train:   9%|▊         | 30/345 [00:33<05:30,  1.05s/it]\u001b[A\n",
      "Processing train:   9%|▉         | 31/345 [00:34<05:28,  1.05s/it]\u001b[A\n",
      "Processing train:   9%|▉         | 32/345 [00:35<05:24,  1.04s/it]\u001b[A\n",
      "Processing train:  10%|▉         | 33/345 [00:36<05:20,  1.03s/it]\u001b[A\n",
      "Processing train:  10%|▉         | 34/345 [00:37<05:18,  1.02s/it]\u001b[A\n",
      "Processing train:  10%|█         | 35/345 [00:38<05:30,  1.07s/it]\u001b[A\n",
      "Processing train:  10%|█         | 36/345 [00:40<05:31,  1.07s/it]\u001b[A\n",
      "Processing train:  11%|█         | 37/345 [00:41<05:26,  1.06s/it]\u001b[A\n",
      "Processing train:  11%|█         | 38/345 [00:42<05:20,  1.04s/it]\u001b[A\n",
      "Processing train:  11%|█▏        | 39/345 [00:43<05:19,  1.04s/it]\u001b[A\n",
      "Processing train:  12%|█▏        | 40/345 [00:44<05:18,  1.04s/it]\u001b[A\n",
      "Processing train:  12%|█▏        | 41/345 [00:45<05:17,  1.05s/it]\u001b[A\n",
      "Processing train:  12%|█▏        | 42/345 [00:46<05:16,  1.05s/it]\u001b[A\n",
      "Processing train:  12%|█▏        | 43/345 [00:47<05:13,  1.04s/it]\u001b[A\n",
      "Processing train:  13%|█▎        | 44/345 [00:48<05:09,  1.03s/it]\u001b[A\n",
      "Processing train:  13%|█▎        | 45/345 [00:49<05:15,  1.05s/it]\u001b[A\n",
      "Processing train:  13%|█▎        | 46/345 [00:50<05:12,  1.04s/it]\u001b[A\n",
      "Processing train:  14%|█▎        | 47/345 [00:51<05:12,  1.05s/it]\u001b[A\n",
      "Processing train:  14%|█▍        | 48/345 [00:52<05:11,  1.05s/it]\u001b[A\n",
      "Processing train:  14%|█▍        | 49/345 [00:53<05:08,  1.04s/it]\u001b[A\n",
      "Processing train:  14%|█▍        | 50/345 [00:54<05:08,  1.05s/it]\u001b[A\n",
      "Processing train:  15%|█▍        | 51/345 [00:55<05:07,  1.04s/it]\u001b[A\n",
      "Processing train:  15%|█▌        | 52/345 [00:56<05:06,  1.05s/it]\u001b[A\n",
      "Processing train:  15%|█▌        | 53/345 [00:57<05:05,  1.04s/it]\u001b[A\n",
      "Processing train:  16%|█▌        | 54/345 [00:58<05:03,  1.04s/it]\u001b[A\n",
      "Processing train:  16%|█▌        | 55/345 [00:59<05:05,  1.05s/it]\u001b[A\n",
      "Processing train:  16%|█▌        | 56/345 [01:00<05:06,  1.06s/it]\u001b[A\n",
      "Processing train:  17%|█▋        | 57/345 [01:01<05:02,  1.05s/it]\u001b[A\n",
      "Processing train:  17%|█▋        | 58/345 [01:04<07:39,  1.60s/it]\u001b[A\n",
      "Processing train:  17%|█▋        | 59/345 [01:05<06:49,  1.43s/it]\u001b[A\n",
      "Processing train:  17%|█▋        | 60/345 [01:06<06:16,  1.32s/it]\u001b[A\n",
      "Processing train:  18%|█▊        | 61/345 [01:07<05:51,  1.24s/it]\u001b[A\n",
      "Processing train:  18%|█▊        | 62/345 [01:09<05:37,  1.19s/it]\u001b[A\n",
      "Processing train:  18%|█▊        | 63/345 [01:10<05:29,  1.17s/it]\u001b[A\n",
      "Processing train:  19%|█▊        | 64/345 [01:11<05:25,  1.16s/it]\u001b[A\n",
      "Processing train:  19%|█▉        | 65/345 [01:12<05:15,  1.13s/it]\u001b[A\n",
      "Processing train:  19%|█▉        | 66/345 [01:13<05:09,  1.11s/it]\u001b[A\n",
      "Processing train:  19%|█▉        | 67/345 [01:14<05:00,  1.08s/it]\u001b[A\n",
      "Processing train:  20%|█▉        | 68/345 [01:15<04:59,  1.08s/it]\u001b[A\n",
      "Processing train:  20%|██        | 69/345 [01:16<04:57,  1.08s/it]\u001b[A\n",
      "Processing train:  20%|██        | 70/345 [01:17<04:52,  1.06s/it]\u001b[A\n",
      "Processing train:  21%|██        | 71/345 [01:18<04:50,  1.06s/it]\u001b[A\n",
      "Processing train:  21%|██        | 72/345 [01:19<04:54,  1.08s/it]\u001b[A\n",
      "Processing train:  21%|██        | 73/345 [01:20<04:57,  1.09s/it]\u001b[A\n",
      "Processing train:  21%|██▏       | 74/345 [01:21<04:54,  1.09s/it]\u001b[A\n",
      "Processing train:  22%|██▏       | 75/345 [01:23<04:50,  1.08s/it]\u001b[A\n",
      "Processing train:  22%|██▏       | 76/345 [01:24<04:47,  1.07s/it]\u001b[A\n",
      "Processing train:  22%|██▏       | 77/345 [01:25<04:47,  1.07s/it]\u001b[A\n",
      "Processing train:  23%|██▎       | 78/345 [01:26<04:46,  1.07s/it]\u001b[A\n",
      "Processing train:  23%|██▎       | 79/345 [01:27<04:47,  1.08s/it]\u001b[A\n",
      "Processing train:  23%|██▎       | 80/345 [01:28<04:43,  1.07s/it]\u001b[A\n",
      "Processing train:  23%|██▎       | 81/345 [01:29<04:42,  1.07s/it]\u001b[A\n",
      "Processing train:  24%|██▍       | 82/345 [01:30<04:41,  1.07s/it]\u001b[A\n",
      "Processing train:  24%|██▍       | 83/345 [01:31<04:44,  1.08s/it]\u001b[A\n",
      "Processing train:  24%|██▍       | 84/345 [01:32<04:40,  1.07s/it]\u001b[A\n",
      "Processing train:  25%|██▍       | 85/345 [01:33<04:37,  1.07s/it]\u001b[A\n",
      "Processing train:  25%|██▍       | 86/345 [01:34<04:35,  1.06s/it]\u001b[A\n",
      "Processing train:  25%|██▌       | 87/345 [01:35<04:34,  1.06s/it]\u001b[A\n",
      "Processing train:  26%|██▌       | 88/345 [01:36<04:35,  1.07s/it]\u001b[A\n",
      "Processing train:  26%|██▌       | 89/345 [01:37<04:32,  1.06s/it]\u001b[A\n",
      "Processing train:  26%|██▌       | 90/345 [01:39<04:35,  1.08s/it]\u001b[A\n",
      "Processing train:  26%|██▋       | 91/345 [01:40<04:29,  1.06s/it]\u001b[A\n",
      "Processing train:  27%|██▋       | 92/345 [01:41<04:27,  1.06s/it]\u001b[A\n",
      "Processing train:  27%|██▋       | 93/345 [01:42<04:32,  1.08s/it]\u001b[A\n",
      "Processing train:  27%|██▋       | 94/345 [01:43<04:32,  1.08s/it]\u001b[A\n",
      "Processing train:  28%|██▊       | 95/345 [01:44<04:26,  1.07s/it]\u001b[A\n",
      "Processing train:  28%|██▊       | 96/345 [01:45<04:22,  1.05s/it]\u001b[A\n",
      "Processing train:  28%|██▊       | 97/345 [01:46<04:19,  1.05s/it]\u001b[A\n",
      "Processing train:  28%|██▊       | 98/345 [01:47<04:17,  1.04s/it]\u001b[A\n",
      "Processing train:  29%|██▊       | 99/345 [01:48<04:18,  1.05s/it]\u001b[A\n",
      "Processing train:  29%|██▉       | 100/345 [01:49<04:19,  1.06s/it]\u001b[A\n",
      "Processing train:  29%|██▉       | 101/345 [01:50<04:17,  1.06s/it]\u001b[A\n",
      "Processing train:  30%|██▉       | 102/345 [01:51<04:14,  1.05s/it]\u001b[A\n",
      "Processing train:  30%|██▉       | 103/345 [01:52<04:13,  1.05s/it]\u001b[A\n",
      "Processing train:  30%|███       | 104/345 [01:53<04:11,  1.05s/it]\u001b[A\n",
      "Processing train:  30%|███       | 105/345 [01:54<04:11,  1.05s/it]\u001b[A\n",
      "Processing train:  31%|███       | 106/345 [01:55<04:11,  1.05s/it]\u001b[A\n",
      "Processing train:  31%|███       | 107/345 [01:57<04:12,  1.06s/it]\u001b[A\n",
      "Processing train:  31%|███▏      | 108/345 [01:58<04:11,  1.06s/it]\u001b[A\n",
      "Processing train:  32%|███▏      | 109/345 [01:59<04:16,  1.09s/it]\u001b[A\n",
      "Processing train:  32%|███▏      | 110/345 [02:00<04:15,  1.09s/it]\u001b[A\n",
      "Processing train:  32%|███▏      | 111/345 [02:01<04:13,  1.08s/it]\u001b[A\n",
      "Processing train:  32%|███▏      | 112/345 [02:02<04:09,  1.07s/it]\u001b[A\n",
      "Processing train:  33%|███▎      | 113/345 [02:03<04:09,  1.07s/it]\u001b[A\n",
      "Processing train:  33%|███▎      | 114/345 [02:04<04:07,  1.07s/it]\u001b[A\n",
      "Processing train:  33%|███▎      | 115/345 [02:05<04:04,  1.06s/it]\u001b[A\n",
      "Processing train:  34%|███▎      | 116/345 [02:06<04:02,  1.06s/it]\u001b[A\n",
      "Processing train:  34%|███▍      | 117/345 [02:07<04:02,  1.06s/it]\u001b[A\n",
      "Processing train:  34%|███▍      | 118/345 [02:08<04:02,  1.07s/it]\u001b[A\n",
      "Processing train:  34%|███▍      | 119/345 [02:09<04:03,  1.08s/it]\u001b[A\n",
      "Processing train:  35%|███▍      | 120/345 [02:10<04:00,  1.07s/it]\u001b[A\n",
      "Processing train:  35%|███▌      | 121/345 [02:12<03:59,  1.07s/it]\u001b[A\n",
      "Processing train:  35%|███▌      | 122/345 [02:13<03:58,  1.07s/it]\u001b[A\n",
      "Processing train:  36%|███▌      | 123/345 [02:14<04:01,  1.09s/it]\u001b[A\n",
      "Processing train:  36%|███▌      | 124/345 [02:15<03:58,  1.08s/it]\u001b[A\n",
      "Processing train:  36%|███▌      | 125/345 [02:16<03:56,  1.07s/it]\u001b[A\n",
      "Processing train:  37%|███▋      | 126/345 [02:17<03:53,  1.07s/it]\u001b[A\n",
      "Processing train:  37%|███▋      | 127/345 [02:18<03:53,  1.07s/it]\u001b[A\n",
      "Processing train:  37%|███▋      | 128/345 [02:19<03:52,  1.07s/it]\u001b[A\n",
      "Processing train:  37%|███▋      | 129/345 [02:20<03:51,  1.07s/it]\u001b[A\n",
      "Processing train:  38%|███▊      | 130/345 [02:21<03:49,  1.07s/it]\u001b[A\n",
      "Processing train:  38%|███▊      | 131/345 [02:22<03:45,  1.05s/it]\u001b[A\n",
      "Processing train:  38%|███▊      | 132/345 [02:23<03:43,  1.05s/it]\u001b[A\n",
      "Processing train:  39%|███▊      | 133/345 [02:24<03:43,  1.05s/it]\u001b[A\n",
      "Processing train:  39%|███▉      | 134/345 [02:25<03:41,  1.05s/it]\u001b[A\n",
      "Processing train:  39%|███▉      | 135/345 [02:26<03:40,  1.05s/it]\u001b[A\n",
      "Processing train:  39%|███▉      | 136/345 [02:27<03:39,  1.05s/it]\u001b[A\n",
      "Processing train:  40%|███▉      | 137/345 [02:29<03:40,  1.06s/it]\u001b[A\n",
      "Processing train:  40%|████      | 138/345 [02:30<03:38,  1.05s/it]\u001b[A\n",
      "Processing train:  40%|████      | 139/345 [02:31<03:35,  1.05s/it]\u001b[A\n",
      "Processing train:  41%|████      | 140/345 [02:32<03:36,  1.06s/it]\u001b[A\n",
      "Processing train:  41%|████      | 141/345 [02:33<03:35,  1.05s/it]\u001b[A\n",
      "Processing train:  41%|████      | 142/345 [02:34<03:32,  1.05s/it]\u001b[A\n",
      "Processing train:  41%|████▏     | 143/345 [02:35<03:30,  1.04s/it]\u001b[A\n",
      "Processing train:  42%|████▏     | 144/345 [02:36<03:29,  1.04s/it]\u001b[A\n",
      "Processing train:  42%|████▏     | 145/345 [02:37<03:29,  1.05s/it]\u001b[A\n",
      "Processing train:  42%|████▏     | 146/345 [02:38<03:25,  1.03s/it]\u001b[A\n",
      "Processing train:  43%|████▎     | 147/345 [02:39<03:27,  1.05s/it]\u001b[A\n",
      "Processing train:  43%|████▎     | 148/345 [02:40<03:28,  1.06s/it]\u001b[A\n",
      "Processing train:  43%|████▎     | 149/345 [02:41<03:26,  1.05s/it]\u001b[A\n",
      "Processing train:  43%|████▎     | 150/345 [02:42<03:24,  1.05s/it]\u001b[A\n",
      "Processing train:  44%|████▍     | 151/345 [02:43<03:23,  1.05s/it]\u001b[A\n",
      "Processing train:  44%|████▍     | 152/345 [02:44<03:25,  1.06s/it]\u001b[A\n",
      "Processing train:  44%|████▍     | 153/345 [02:45<03:24,  1.07s/it]\u001b[A\n",
      "Processing train:  45%|████▍     | 154/345 [02:46<03:22,  1.06s/it]\u001b[A\n",
      "Processing train:  45%|████▍     | 155/345 [02:47<03:20,  1.06s/it]\u001b[A\n",
      "Processing train:  45%|████▌     | 156/345 [02:49<03:20,  1.06s/it]\u001b[A\n",
      "Processing train:  46%|████▌     | 157/345 [02:50<03:20,  1.06s/it]\u001b[A\n",
      "Processing train:  46%|████▌     | 158/345 [02:51<03:18,  1.06s/it]\u001b[A\n",
      "Processing train:  46%|████▌     | 159/345 [02:52<03:15,  1.05s/it]\u001b[A\n",
      "Processing train:  46%|████▋     | 160/345 [02:53<03:12,  1.04s/it]\u001b[A\n",
      "Processing train:  47%|████▋     | 161/345 [02:54<03:10,  1.03s/it]\u001b[A\n",
      "Processing train:  47%|████▋     | 162/345 [02:55<03:08,  1.03s/it]\u001b[A\n",
      "Processing train:  47%|████▋     | 163/345 [02:56<03:06,  1.03s/it]\u001b[A\n",
      "Processing train:  48%|████▊     | 164/345 [02:57<03:08,  1.04s/it]\u001b[A\n",
      "Processing train:  48%|████▊     | 165/345 [02:58<03:07,  1.04s/it]\u001b[A\n",
      "Processing train:  48%|████▊     | 166/345 [02:59<03:08,  1.05s/it]\u001b[A\n",
      "Processing train:  48%|████▊     | 167/345 [03:00<03:07,  1.05s/it]\u001b[A\n",
      "Processing train:  49%|████▊     | 168/345 [03:01<03:06,  1.06s/it]\u001b[A\n",
      "Processing train:  49%|████▉     | 169/345 [03:02<03:04,  1.05s/it]\u001b[A\n",
      "Processing train:  49%|████▉     | 170/345 [03:03<03:05,  1.06s/it]\u001b[A\n",
      "Processing train:  50%|████▉     | 171/345 [03:04<03:04,  1.06s/it]\u001b[A\n",
      "Processing train:  50%|████▉     | 172/345 [03:05<03:05,  1.07s/it]\u001b[A\n",
      "Processing train:  50%|█████     | 173/345 [03:06<03:04,  1.07s/it]\u001b[A\n",
      "Processing train:  50%|█████     | 174/345 [03:08<03:02,  1.07s/it]\u001b[A\n",
      "Processing train:  51%|█████     | 175/345 [03:09<03:01,  1.07s/it]\u001b[A\n",
      "Processing train:  51%|█████     | 176/345 [03:10<03:00,  1.07s/it]\u001b[A\n",
      "Processing train:  51%|█████▏    | 177/345 [03:11<02:58,  1.06s/it]\u001b[A\n",
      "Processing train:  52%|█████▏    | 178/345 [03:12<02:56,  1.06s/it]\u001b[A\n",
      "Processing train:  52%|█████▏    | 179/345 [03:13<02:55,  1.06s/it]\u001b[A\n",
      "Processing train:  52%|█████▏    | 180/345 [03:14<02:54,  1.06s/it]\u001b[A\n",
      "Processing train:  52%|█████▏    | 181/345 [03:15<02:51,  1.05s/it]\u001b[A\n",
      "Processing train:  53%|█████▎    | 182/345 [03:16<02:53,  1.07s/it]\u001b[A\n",
      "Processing train:  53%|█████▎    | 183/345 [03:17<02:54,  1.08s/it]\u001b[A\n",
      "Processing train:  53%|█████▎    | 184/345 [03:18<02:52,  1.07s/it]\u001b[A\n",
      "Processing train:  54%|█████▎    | 185/345 [03:19<02:52,  1.08s/it]\u001b[A\n",
      "Processing train:  54%|█████▍    | 186/345 [03:20<02:50,  1.07s/it]\u001b[A\n",
      "Processing train:  54%|█████▍    | 187/345 [03:21<02:48,  1.07s/it]\u001b[A\n",
      "Processing train:  54%|█████▍    | 188/345 [03:22<02:45,  1.06s/it]\u001b[A\n",
      "Processing train:  55%|█████▍    | 189/345 [03:23<02:45,  1.06s/it]\u001b[A\n",
      "Processing train:  55%|█████▌    | 190/345 [03:25<02:45,  1.07s/it]\u001b[A\n",
      "Processing train:  55%|█████▌    | 191/345 [03:26<02:42,  1.06s/it]\u001b[A\n",
      "Processing train:  56%|█████▌    | 192/345 [03:27<02:40,  1.05s/it]\u001b[A\n",
      "Processing train:  56%|█████▌    | 193/345 [03:28<02:38,  1.05s/it]\u001b[A\n",
      "Processing train:  56%|█████▌    | 194/345 [03:29<02:40,  1.06s/it]\u001b[A\n",
      "Processing train:  57%|█████▋    | 195/345 [03:30<02:38,  1.05s/it]\u001b[A\n",
      "Processing train:  57%|█████▋    | 196/345 [03:31<02:37,  1.06s/it]\u001b[A\n",
      "Processing train:  57%|█████▋    | 197/345 [03:32<02:37,  1.06s/it]\u001b[A\n",
      "Processing train:  57%|█████▋    | 198/345 [03:33<02:35,  1.06s/it]\u001b[A\n",
      "Processing train:  58%|█████▊    | 199/345 [03:34<02:34,  1.06s/it]\u001b[A\n",
      "Processing train:  58%|█████▊    | 200/345 [03:35<02:34,  1.06s/it]\u001b[A\n",
      "Processing train:  58%|█████▊    | 201/345 [03:36<02:34,  1.07s/it]\u001b[A\n",
      "Processing train:  59%|█████▊    | 202/345 [03:37<02:31,  1.06s/it]\u001b[A\n",
      "Processing train:  59%|█████▉    | 203/345 [03:38<02:30,  1.06s/it]\u001b[A\n",
      "Processing train:  59%|█████▉    | 204/345 [03:39<02:30,  1.07s/it]\u001b[A\n",
      "Processing train:  59%|█████▉    | 205/345 [03:40<02:29,  1.07s/it]\u001b[A\n",
      "Processing train:  60%|█████▉    | 206/345 [03:41<02:27,  1.06s/it]\u001b[A\n",
      "Processing train:  60%|██████    | 207/345 [03:43<02:26,  1.06s/it]\u001b[A\n",
      "Processing train:  60%|██████    | 208/345 [03:44<02:23,  1.05s/it]\u001b[A\n",
      "Processing train:  61%|██████    | 209/345 [03:45<02:22,  1.05s/it]\u001b[A\n",
      "Processing train:  61%|██████    | 210/345 [03:46<02:21,  1.05s/it]\u001b[A\n",
      "Processing train:  61%|██████    | 211/345 [03:47<02:20,  1.05s/it]\u001b[A\n",
      "Processing train:  61%|██████▏   | 212/345 [03:48<02:22,  1.07s/it]\u001b[A\n",
      "Processing train:  62%|██████▏   | 213/345 [03:49<02:21,  1.07s/it]\u001b[A\n",
      "Processing train:  62%|██████▏   | 214/345 [03:50<02:18,  1.06s/it]\u001b[A\n",
      "Processing train:  62%|██████▏   | 215/345 [03:51<02:17,  1.06s/it]\u001b[A\n",
      "Processing train:  63%|██████▎   | 216/345 [03:52<02:16,  1.06s/it]\u001b[A\n",
      "Processing train:  63%|██████▎   | 217/345 [03:53<02:14,  1.05s/it]\u001b[A\n",
      "Processing train:  63%|██████▎   | 218/345 [03:54<02:13,  1.05s/it]\u001b[A\n",
      "Processing train:  63%|██████▎   | 219/345 [03:55<02:12,  1.05s/it]\u001b[A\n",
      "Processing train:  64%|██████▍   | 220/345 [03:56<02:13,  1.07s/it]\u001b[A\n",
      "Processing train:  64%|██████▍   | 221/345 [03:57<02:13,  1.08s/it]\u001b[A\n",
      "Processing train:  64%|██████▍   | 222/345 [03:58<02:13,  1.08s/it]\u001b[A\n",
      "Processing train:  65%|██████▍   | 223/345 [04:00<02:11,  1.08s/it]\u001b[A\n",
      "Processing train:  65%|██████▍   | 224/345 [04:01<02:10,  1.08s/it]\u001b[A\n",
      "Processing train:  65%|██████▌   | 225/345 [04:02<02:07,  1.06s/it]\u001b[A\n",
      "Processing train:  66%|██████▌   | 226/345 [04:03<02:05,  1.05s/it]\u001b[A\n",
      "Processing train:  66%|██████▌   | 227/345 [04:04<02:04,  1.05s/it]\u001b[A\n",
      "Processing train:  66%|██████▌   | 228/345 [04:05<02:03,  1.06s/it]\u001b[A\n",
      "Processing train:  66%|██████▋   | 229/345 [04:06<02:02,  1.06s/it]\u001b[A\n",
      "Processing train:  67%|██████▋   | 230/345 [04:07<02:02,  1.06s/it]\u001b[A\n",
      "Processing train:  67%|██████▋   | 231/345 [04:08<02:02,  1.07s/it]\u001b[A\n",
      "Processing train:  67%|██████▋   | 232/345 [04:09<02:01,  1.07s/it]\u001b[A\n",
      "Processing train:  68%|██████▊   | 233/345 [04:10<02:00,  1.07s/it]\u001b[A\n",
      "Processing train:  68%|██████▊   | 234/345 [04:11<01:57,  1.06s/it]\u001b[A\n",
      "Processing train:  68%|██████▊   | 235/345 [04:12<01:56,  1.06s/it]\u001b[A\n",
      "Processing train:  68%|██████▊   | 236/345 [04:13<01:55,  1.06s/it]\u001b[A\n",
      "Processing train:  69%|██████▊   | 237/345 [04:14<01:54,  1.06s/it]\u001b[A\n",
      "Processing train:  69%|██████▉   | 238/345 [04:15<01:53,  1.06s/it]\u001b[A\n",
      "Processing train:  69%|██████▉   | 239/345 [04:17<01:52,  1.06s/it]\u001b[A\n",
      "Processing train:  70%|██████▉   | 240/345 [04:18<01:50,  1.06s/it]\u001b[A\n",
      "Processing train:  70%|██████▉   | 241/345 [04:19<01:52,  1.08s/it]\u001b[A\n",
      "Processing train:  70%|███████   | 242/345 [04:20<01:52,  1.09s/it]\u001b[A\n",
      "Processing train:  70%|███████   | 243/345 [04:21<01:50,  1.08s/it]\u001b[A\n",
      "Processing train:  71%|███████   | 244/345 [04:22<01:48,  1.07s/it]\u001b[A\n",
      "Processing train:  71%|███████   | 245/345 [04:23<01:46,  1.06s/it]\u001b[A\n",
      "Processing train:  71%|███████▏  | 246/345 [04:24<01:45,  1.07s/it]\u001b[A\n",
      "Processing train:  72%|███████▏  | 247/345 [04:25<01:43,  1.06s/it]\u001b[A\n",
      "Processing train:  72%|███████▏  | 248/345 [04:26<01:42,  1.05s/it]\u001b[A\n",
      "Processing train:  72%|███████▏  | 249/345 [04:27<01:41,  1.06s/it]\u001b[A\n",
      "Processing train:  72%|███████▏  | 250/345 [04:28<01:40,  1.06s/it]\u001b[A\n",
      "Processing train:  73%|███████▎  | 251/345 [04:29<01:40,  1.06s/it]\u001b[A\n",
      "Processing train:  73%|███████▎  | 252/345 [04:30<01:38,  1.06s/it]\u001b[A\n",
      "Processing train:  73%|███████▎  | 253/345 [04:31<01:37,  1.06s/it]\u001b[A\n",
      "Processing train:  74%|███████▎  | 254/345 [04:33<01:37,  1.07s/it]\u001b[A\n",
      "Processing train:  74%|███████▍  | 255/345 [04:34<01:35,  1.06s/it]\u001b[A\n",
      "Processing train:  74%|███████▍  | 256/345 [04:35<01:33,  1.05s/it]\u001b[A\n",
      "Processing train:  74%|███████▍  | 257/345 [04:36<01:31,  1.04s/it]\u001b[A\n",
      "Processing train:  75%|███████▍  | 258/345 [04:37<01:30,  1.04s/it]\u001b[A\n",
      "Processing train:  75%|███████▌  | 259/345 [04:38<01:29,  1.05s/it]\u001b[A\n",
      "Processing train:  75%|███████▌  | 260/345 [04:39<01:30,  1.06s/it]\u001b[A\n",
      "Processing train:  76%|███████▌  | 261/345 [04:40<01:29,  1.07s/it]\u001b[A\n",
      "Processing train:  76%|███████▌  | 262/345 [04:41<01:27,  1.06s/it]\u001b[A\n",
      "Processing train:  76%|███████▌  | 263/345 [04:42<01:26,  1.06s/it]\u001b[A\n",
      "Processing train:  77%|███████▋  | 264/345 [04:43<01:25,  1.06s/it]\u001b[A\n",
      "Processing train:  77%|███████▋  | 265/345 [04:44<01:24,  1.06s/it]\u001b[A\n",
      "Processing train:  77%|███████▋  | 266/345 [04:45<01:22,  1.05s/it]\u001b[A\n",
      "Processing train:  77%|███████▋  | 267/345 [04:46<01:22,  1.05s/it]\u001b[A\n",
      "Processing train:  78%|███████▊  | 268/345 [04:47<01:21,  1.05s/it]\u001b[A\n",
      "Processing train:  78%|███████▊  | 269/345 [04:48<01:19,  1.05s/it]\u001b[A\n",
      "Processing train:  78%|███████▊  | 270/345 [04:49<01:18,  1.05s/it]\u001b[A\n",
      "Processing train:  79%|███████▊  | 271/345 [04:50<01:18,  1.06s/it]\u001b[A\n",
      "Processing train:  79%|███████▉  | 272/345 [04:52<01:18,  1.08s/it]\u001b[A\n",
      "Processing train:  79%|███████▉  | 273/345 [04:53<01:17,  1.08s/it]\u001b[A\n",
      "Processing train:  79%|███████▉  | 274/345 [04:54<01:15,  1.07s/it]\u001b[A\n",
      "Processing train:  80%|███████▉  | 275/345 [04:55<01:14,  1.06s/it]\u001b[A\n",
      "Processing train:  80%|████████  | 276/345 [04:56<01:12,  1.05s/it]\u001b[A\n",
      "Processing train:  80%|████████  | 277/345 [04:57<01:11,  1.04s/it]\u001b[A\n",
      "Processing train:  81%|████████  | 278/345 [04:58<01:10,  1.05s/it]\u001b[A\n",
      "Processing train:  81%|████████  | 279/345 [04:59<01:10,  1.06s/it]\u001b[A\n",
      "Processing train:  81%|████████  | 280/345 [05:00<01:08,  1.05s/it]\u001b[A\n",
      "Processing train:  81%|████████▏ | 281/345 [05:01<01:07,  1.05s/it]\u001b[A\n",
      "Processing train:  82%|████████▏ | 282/345 [05:02<01:06,  1.06s/it]\u001b[A\n",
      "Processing train:  82%|████████▏ | 283/345 [05:03<01:05,  1.06s/it]\u001b[A\n",
      "Processing train:  82%|████████▏ | 284/345 [05:04<01:04,  1.06s/it]\u001b[A\n",
      "Processing train:  83%|████████▎ | 285/345 [05:05<01:04,  1.07s/it]\u001b[A\n",
      "Processing train:  83%|████████▎ | 286/345 [05:06<01:02,  1.06s/it]\u001b[A\n",
      "Processing train:  83%|████████▎ | 287/345 [05:07<01:02,  1.07s/it]\u001b[A\n",
      "Processing train:  83%|████████▎ | 288/345 [05:08<01:01,  1.08s/it]\u001b[A\n",
      "Processing train:  84%|████████▍ | 289/345 [05:10<01:00,  1.08s/it]\u001b[A\n",
      "Processing train:  84%|████████▍ | 290/345 [05:11<00:58,  1.07s/it]\u001b[A\n",
      "Processing train:  84%|████████▍ | 291/345 [05:12<00:57,  1.07s/it]\u001b[A\n",
      "Processing train:  85%|████████▍ | 292/345 [05:13<00:56,  1.07s/it]\u001b[A\n",
      "Processing train:  85%|████████▍ | 293/345 [05:14<00:55,  1.07s/it]\u001b[A\n",
      "Processing train:  85%|████████▌ | 294/345 [05:15<00:54,  1.07s/it]\u001b[A\n",
      "Processing train:  86%|████████▌ | 295/345 [05:16<00:53,  1.07s/it]\u001b[A\n",
      "Processing train:  86%|████████▌ | 296/345 [05:17<00:51,  1.06s/it]\u001b[A\n",
      "Processing train:  86%|████████▌ | 297/345 [05:18<00:50,  1.06s/it]\u001b[A\n",
      "Processing train:  86%|████████▋ | 298/345 [05:19<00:50,  1.07s/it]\u001b[A\n",
      "Processing train:  87%|████████▋ | 299/345 [05:20<00:49,  1.07s/it]\u001b[A\n",
      "Processing train:  87%|████████▋ | 300/345 [05:21<00:47,  1.06s/it]\u001b[A\n",
      "Processing train:  87%|████████▋ | 301/345 [05:22<00:47,  1.07s/it]\u001b[A\n",
      "Processing train:  88%|████████▊ | 302/345 [05:23<00:46,  1.07s/it]\u001b[A\n",
      "Processing train:  88%|████████▊ | 303/345 [05:24<00:44,  1.07s/it]\u001b[A\n",
      "Processing train:  88%|████████▊ | 304/345 [05:26<00:43,  1.07s/it]\u001b[A\n",
      "Processing train:  88%|████████▊ | 305/345 [05:27<00:42,  1.07s/it]\u001b[A\n",
      "Processing train:  89%|████████▊ | 306/345 [05:28<00:40,  1.05s/it]\u001b[A\n",
      "Processing train:  89%|████████▉ | 307/345 [05:29<00:40,  1.07s/it]\u001b[A\n",
      "Processing train:  89%|████████▉ | 308/345 [05:30<00:39,  1.07s/it]\u001b[A\n",
      "Processing train:  90%|████████▉ | 309/345 [05:31<00:38,  1.07s/it]\u001b[A\n",
      "Processing train:  90%|████████▉ | 310/345 [05:32<00:37,  1.07s/it]\u001b[A\n",
      "Processing train:  90%|█████████ | 311/345 [05:33<00:36,  1.07s/it]\u001b[A\n",
      "Processing train:  90%|█████████ | 312/345 [05:34<00:35,  1.06s/it]\u001b[A\n",
      "Processing train:  91%|█████████ | 313/345 [05:35<00:34,  1.07s/it]\u001b[A\n",
      "Processing train:  91%|█████████ | 314/345 [05:36<00:32,  1.06s/it]\u001b[A\n",
      "Processing train:  91%|█████████▏| 315/345 [05:37<00:31,  1.06s/it]\u001b[A\n",
      "Processing train:  92%|█████████▏| 316/345 [05:38<00:30,  1.06s/it]\u001b[A\n",
      "Processing train:  92%|█████████▏| 317/345 [05:39<00:29,  1.07s/it]\u001b[A\n",
      "Processing train:  92%|█████████▏| 318/345 [05:40<00:28,  1.07s/it]\u001b[A\n",
      "Processing train:  92%|█████████▏| 319/345 [05:42<00:27,  1.07s/it]\u001b[A\n",
      "Processing train:  93%|█████████▎| 320/345 [05:43<00:26,  1.07s/it]\u001b[A\n",
      "Processing train:  93%|█████████▎| 321/345 [05:44<00:25,  1.07s/it]\u001b[A\n",
      "Processing train:  93%|█████████▎| 322/345 [05:45<00:24,  1.06s/it]\u001b[A\n",
      "Processing train:  94%|█████████▎| 323/345 [05:46<00:23,  1.07s/it]\u001b[A\n",
      "Processing train:  94%|█████████▍| 324/345 [05:47<00:22,  1.07s/it]\u001b[A\n",
      "Processing train:  94%|█████████▍| 325/345 [05:48<00:21,  1.06s/it]\u001b[A\n",
      "Processing train:  94%|█████████▍| 326/345 [05:49<00:20,  1.06s/it]\u001b[A\n",
      "Processing train:  95%|█████████▍| 327/345 [05:50<00:18,  1.05s/it]\u001b[A\n",
      "Processing train:  95%|█████████▌| 328/345 [05:51<00:17,  1.04s/it]\u001b[A\n",
      "Processing train:  95%|█████████▌| 329/345 [05:52<00:16,  1.04s/it]\u001b[A\n",
      "Processing train:  96%|█████████▌| 330/345 [05:53<00:15,  1.05s/it]\u001b[A\n",
      "Processing train:  96%|█████████▌| 331/345 [05:54<00:14,  1.07s/it]\u001b[A\n",
      "Processing train:  96%|█████████▌| 332/345 [05:55<00:13,  1.07s/it]\u001b[A\n",
      "Processing train:  97%|█████████▋| 333/345 [05:56<00:12,  1.07s/it]\u001b[A\n",
      "Processing train:  97%|█████████▋| 334/345 [05:57<00:11,  1.07s/it]\u001b[A\n",
      "Processing train:  97%|█████████▋| 335/345 [05:59<00:10,  1.08s/it]\u001b[A\n",
      "Processing train:  97%|█████████▋| 336/345 [06:00<00:09,  1.07s/it]\u001b[A\n",
      "Processing train:  98%|█████████▊| 337/345 [06:01<00:08,  1.07s/it]\u001b[A\n",
      "Processing train:  98%|█████████▊| 338/345 [06:02<00:07,  1.06s/it]\u001b[A\n",
      "Processing train:  98%|█████████▊| 339/345 [06:03<00:06,  1.05s/it]\u001b[A\n",
      "Processing train:  99%|█████████▊| 340/345 [06:04<00:05,  1.05s/it]\u001b[A\n",
      "Processing train:  99%|█████████▉| 341/345 [06:05<00:04,  1.06s/it]\u001b[A\n",
      "Processing train:  99%|█████████▉| 342/345 [06:06<00:03,  1.05s/it]\u001b[A\n",
      "Processing train:  99%|█████████▉| 343/345 [06:07<00:02,  1.06s/it]\u001b[A\n",
      "Processing train: 100%|█████████▉| 344/345 [06:08<00:01,  1.05s/it]\u001b[A\n",
      "Processing train: 100%|██████████| 345/345 [06:09<00:00,  1.07s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train dataset with 345 examples\n",
      "Generating embeddings for train...\n",
      "Processing batch 0 to 4 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "Fitting PCA to reduce dimensions from 768 to 400\n",
      "PCA fitted, explained variance ratio sum: 0.9124\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 4 to 8 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 8 to 12 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 12 to 16 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 16 to 20 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 20 to 24 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 24 to 28 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 28 to 32 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 32 to 36 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 36 to 40 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 40 to 44 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 44 to 48 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 48 to 52 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 52 to 56 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 56 to 60 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 60 to 64 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 64 to 68 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 68 to 72 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 72 to 76 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 76 to 80 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 80 to 84 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 84 to 88 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 88 to 92 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 92 to 96 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 96 to 100 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 100 to 104 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 104 to 108 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 108 to 112 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 112 to 116 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 116 to 120 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 120 to 124 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 124 to 128 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 128 to 132 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 132 to 136 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 136 to 140 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 140 to 144 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 144 to 148 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 148 to 152 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 152 to 156 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 156 to 160 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 160 to 164 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 164 to 168 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 168 to 172 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 172 to 176 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 176 to 180 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 180 to 184 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 184 to 188 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 188 to 192 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 192 to 196 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 196 to 200 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 200 to 204 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 204 to 208 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 208 to 212 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 212 to 216 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 216 to 220 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 220 to 224 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 224 to 228 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 228 to 232 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 232 to 236 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 236 to 240 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 240 to 244 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 244 to 248 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 248 to 252 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 252 to 256 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 256 to 260 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 260 to 264 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 264 to 268 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 268 to 272 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 272 to 276 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 276 to 280 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 280 to 284 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 284 to 288 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 288 to 292 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 292 to 296 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 296 to 300 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 300 to 304 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 304 to 308 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 308 to 312 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 312 to 316 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 316 to 320 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 320 to 324 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 324 to 328 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 328 to 332 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 332 to 336 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 336 to 340 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 340 to 344 of 345\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 344 to 345 of 345\n",
      "Input shapes - news: torch.Size([1, 9, 10, 128, 768]), metrics: torch.Size([1, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([1, 9, 128, 400])\n",
      "After weighted sum: torch.Size([1, 9, 400])\n",
      "News features final shape: torch.Size([1, 9, 128])\n",
      "Metrics features shape: torch.Size([1, 9, 384])\n",
      "Combined shape: torch.Size([1, 9, 512])\n",
      "Temporal features shape: torch.Size([1, 9, 312])\n",
      "Saved train embeddings with shape torch.Size([345, 9, 312]) to data/preprocessed/train_embeddings_9x312.pt\n",
      "\n",
      "Processing val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing val: 100%|██████████| 44/44 [00:47<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved val dataset with 44 examples\n",
      "Generating embeddings for val...\n",
      "Processing batch 0 to 4 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 4 to 8 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 8 to 12 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 12 to 16 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 16 to 20 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 20 to 24 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 24 to 28 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 28 to 32 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 32 to 36 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 36 to 40 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 40 to 44 of 44\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Saved val embeddings with shape torch.Size([44, 9, 312]) to data/preprocessed/val_embeddings_9x312.pt\n",
      "\n",
      "Processing test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing test: 100%|██████████| 43/43 [00:47<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test dataset with 43 examples\n",
      "Generating embeddings for test...\n",
      "Processing batch 0 to 4 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 4 to 8 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 8 to 12 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 12 to 16 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 16 to 20 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 20 to 24 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 24 to 28 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 28 to 32 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 32 to 36 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 36 to 40 of 43\n",
      "Input shapes - news: torch.Size([4, 9, 10, 128, 768]), metrics: torch.Size([4, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([4, 9, 128, 400])\n",
      "After weighted sum: torch.Size([4, 9, 400])\n",
      "News features final shape: torch.Size([4, 9, 128])\n",
      "Metrics features shape: torch.Size([4, 9, 384])\n",
      "Combined shape: torch.Size([4, 9, 512])\n",
      "Temporal features shape: torch.Size([4, 9, 312])\n",
      "Processing batch 40 to 43 of 43\n",
      "Input shapes - news: torch.Size([3, 9, 10, 128, 768]), metrics: torch.Size([3, 9, 6, 5])\n",
      "After PCA and article averaging: torch.Size([3, 9, 128, 400])\n",
      "After weighted sum: torch.Size([3, 9, 400])\n",
      "News features final shape: torch.Size([3, 9, 128])\n",
      "Metrics features shape: torch.Size([3, 9, 384])\n",
      "Combined shape: torch.Size([3, 9, 512])\n",
      "Temporal features shape: torch.Size([3, 9, 312])\n",
      "Saved test embeddings with shape torch.Size([43, 9, 312]) to data/preprocessed/test_embeddings_9x312.pt\n",
      "\n",
      "=== Dataset Summary ===\n",
      "Train split:\n",
      "  • Examples: 345\n",
      "  • News tensor: torch.Size([345, 9, 10, 128, 768])\n",
      "  • Metrics tensor: torch.Size([345, 9, 6, 5])\n",
      "  • Targets tensor: torch.Size([345, 30])\n",
      "  • Embeddings tensor: torch.Size([345, 9, 312])\n",
      "Val split:\n",
      "  • Examples: 44\n",
      "  • News tensor: torch.Size([44, 9, 10, 128, 768])\n",
      "  • Metrics tensor: torch.Size([44, 9, 6, 5])\n",
      "  • Targets tensor: torch.Size([44, 30])\n",
      "  • Embeddings tensor: torch.Size([44, 9, 312])\n",
      "Test split:\n",
      "  • Examples: 43\n",
      "  • News tensor: torch.Size([43, 9, 10, 128, 768])\n",
      "  • Metrics tensor: torch.Size([43, 9, 6, 5])\n",
      "  • Targets tensor: torch.Size([43, 30])\n",
      "  • Embeddings tensor: torch.Size([43, 9, 312])\n",
      "\n",
      "✅ Processing complete. Generated [batch×9×312] embeddings for all splits.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# === Device Setup ===\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === FinBERT Model ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "finbert_model = AutoModel.from_pretrained(\"yiyanghkust/finbert-tone\").to(device)\n",
    "finbert_model.eval()\n",
    "\n",
    "# === PCA Dimensionality Reduction ===\n",
    "class PCAReducer:\n",
    "    def __init__(self, input_dim=768, output_dim=400):\n",
    "        self.pca = PCA(n_components=output_dim)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.is_fitted = False\n",
    "    \n",
    "    def fit(self, data):\n",
    "        # data shape: [N, input_dim]\n",
    "        print(f\"Fitting PCA to reduce dimensions from {self.input_dim} to {self.output_dim}\")\n",
    "        self.pca.fit(data.cpu().numpy())\n",
    "        self.is_fitted = True\n",
    "        print(f\"PCA fitted, explained variance ratio sum: {sum(self.pca.explained_variance_ratio_):.4f}\")\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # data shape: [..., input_dim]\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"PCA must be fitted before transforming data\")\n",
    "        \n",
    "        original_shape = data.shape\n",
    "        # Reshape to 2D for PCA\n",
    "        data_2d = data.reshape(-1, self.input_dim)\n",
    "        \n",
    "        # Transform using PCA\n",
    "        if isinstance(data, torch.Tensor):\n",
    "            data_2d_np = data_2d.cpu().numpy()\n",
    "            reduced_data_np = self.pca.transform(data_2d_np)\n",
    "            reduced_data = torch.from_numpy(reduced_data_np).to(data.device)\n",
    "        else:\n",
    "            reduced_data = torch.from_numpy(self.pca.transform(data_2d)).to(device)\n",
    "            \n",
    "        # Reshape back to original dimensions but with reduced feature size\n",
    "        new_shape = list(original_shape)\n",
    "        new_shape[-1] = self.output_dim\n",
    "        return reduced_data.reshape(new_shape)\n",
    "\n",
    "# === Define LSTM Network for Financial Metrics ===\n",
    "class FinancialLSTMNet(nn.Module):\n",
    "    def __init__(self, in_channels=6, kernel_size=3, hidden_dim=64, stocks_count=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        # We'll keep the same parameter names for drop-in compatibility\n",
    "        # but kernel_size won't be used in this implementation\n",
    "        self.in_channels = in_channels  # Number of financial metrics\n",
    "        self.hidden_dim = hidden_dim    # Hidden dimensions in LSTM\n",
    "        self.stocks_count = stocks_count  # Number of stocks\n",
    "        \n",
    "        # Separate LSTM layer for each metric\n",
    "        self.lstm_layers = nn.ModuleList([\n",
    "            nn.LSTM(\n",
    "                input_size=stocks_count,     # Each stock is a feature\n",
    "                hidden_size=hidden_dim,      # Hidden dimension per metric\n",
    "                batch_first=True,            # Expect [batch, seq, features]\n",
    "                num_layers=1                 # Single layer LSTM\n",
    "            ) for _ in range(in_channels)\n",
    "        ])\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        # Dimension reducer after LSTM, same as the original\n",
    "        self.metrics_dim_reducer = nn.Linear(hidden_dim * in_channels, 384)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_length, metrics, stocks]\n",
    "        batch_size, seq_len, metrics, stocks = x.shape\n",
    "        assert metrics == self.in_channels\n",
    "        assert stocks == self.stocks_count\n",
    "        \n",
    "        # Process all days in sequence\n",
    "        all_days_features = []\n",
    "        \n",
    "        for day_idx in range(seq_len):\n",
    "            day_features = []\n",
    "            \n",
    "            # Process each metric\n",
    "            for metric_idx in range(metrics):\n",
    "                # Extract the time series for each stock for this specific metric\n",
    "                # Shape: [batch_size, seq_length, stocks]\n",
    "                metric_data = x[:, :, metric_idx, :]\n",
    "                \n",
    "                # Process through LSTM\n",
    "                # Output shape: [batch_size, seq_length, hidden_dim]\n",
    "                lstm_output, _ = self.lstm_layers[metric_idx](metric_data)\n",
    "                \n",
    "                # Extract features for the current day\n",
    "                # Shape: [batch_size, hidden_dim]\n",
    "                day_metric_features = lstm_output[:, day_idx, :]\n",
    "                \n",
    "                day_features.append(day_metric_features)\n",
    "            \n",
    "            # Combine all metric features for this day\n",
    "            # Shape: [batch_size, metrics*hidden_dim]\n",
    "            combined_day_features = torch.cat(day_features, dim=1)\n",
    "            \n",
    "            # Apply dimension reduction\n",
    "            # Shape: [batch_size, 384]\n",
    "            day_output = self.tanh(self.metrics_dim_reducer(combined_day_features))\n",
    "            \n",
    "            all_days_features.append(day_output)\n",
    "        \n",
    "        # Stack all days features\n",
    "        # Shape: [batch_size, seq_length, 384]\n",
    "        return torch.stack(all_days_features, dim=1)\n",
    "\n",
    "# === Modified News Processor with Memory-Efficient Processing ===\n",
    "class MemoryEfficientNewsProcessor(nn.Module):\n",
    "    def __init__(self, input_dim=400):  # Changed from 768 to 400\n",
    "        super().__init__()\n",
    "        # Attention for token weighting\n",
    "        self.token_attention = nn.Linear(input_dim, 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_length=9, tokens=128, features=400]\n",
    "        # Note: We've already averaged across the 10 articles before this stage\n",
    "        batch_size, seq_len, num_tokens, features = x.shape\n",
    "        \n",
    "        # Process each day separately to save memory\n",
    "        processed_days = []\n",
    "        for day in range(seq_len):\n",
    "            # Get current day: [batch_size, 128, 400]\n",
    "            day_data = x[:, day]\n",
    "            \n",
    "            # Calculate attention weights for tokens\n",
    "            # Shape: [batch_size, 128, 1]\n",
    "            attn_weights = F.softmax(self.token_attention(day_data), dim=1)\n",
    "            \n",
    "            # Apply attention to get weighted representation\n",
    "            # Shape: [batch_size, 400]\n",
    "            day_repr = torch.sum(day_data * attn_weights, dim=1)\n",
    "            \n",
    "            # Apply tanh directly as specified\n",
    "            day_repr = self.tanh(day_repr)\n",
    "            \n",
    "            processed_days.append(day_repr)\n",
    "            \n",
    "        # Stack back to [batch_size, 9, 128]\n",
    "        return torch.stack(processed_days, dim=1)\n",
    "\n",
    "# === Modified Combined Model with PCA Reduction ===\n",
    "class CombinedFinancialModel(nn.Module):\n",
    "    def __init__(self, pca_dim=400, metrics_count=6, stocks_count=5, output_dim=312, pred_metrics=6):\n",
    "        super().__init__()\n",
    "\n",
    "        # PCA reducer for FinBERT embeddings\n",
    "        self.pca_reducer = PCAReducer(input_dim=768, output_dim=pca_dim)\n",
    "        \n",
    "        # News processing branch\n",
    "        # This will reduce token dimension with weighted sum\n",
    "        self.news_processor = MemoryEfficientNewsProcessor(input_dim=pca_dim)\n",
    "        \n",
    "        # Linear layer to reduce news embedding dimension from pca_dim to 128\n",
    "        self.news_dim_reducer = nn.Linear(pca_dim, 128)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        # Metrics processing - changed from ConvNet to LSTMNet\n",
    "        self.lstm_net = FinancialLSTMNet(in_channels=metrics_count, kernel_size=3, stocks_count=stocks_count)\n",
    "\n",
    "        # Combined processing\n",
    "        self.concat_reducer = nn.Linear(128 + 384, output_dim)  # 128 from news branch + 384 from metrics\n",
    "\n",
    "        # Prediction layer for next day (day 10)\n",
    "        self.predictor = nn.Linear(output_dim * 9, pred_metrics * stocks_count)\n",
    "\n",
    "    def forward(self, news_embeddings, metrics_data):\n",
    "        batch_size, seq_len, num_articles, num_tokens, features = news_embeddings.shape\n",
    "        print(f\"Input shapes - news: {news_embeddings.shape}, metrics: {metrics_data.shape}\")\n",
    "        \n",
    "        # Step 1: Apply PCA to reduce from 768 to 400 dimensions\n",
    "        if not self.pca_reducer.is_fitted:\n",
    "            flattened_data = news_embeddings.reshape(-1, features)\n",
    "            max_samples = min(100000, flattened_data.shape[0])\n",
    "            sample_indices = torch.randperm(flattened_data.shape[0])[:max_samples]\n",
    "            self.pca_reducer.fit(flattened_data[sample_indices])\n",
    "        \n",
    "        # Transform the data - process in chunks to save memory\n",
    "        reduced_embeddings = []\n",
    "        chunk_size = 2\n",
    "        for i in range(0, batch_size, chunk_size):\n",
    "            end_idx = min(i + chunk_size, batch_size)\n",
    "            chunk = news_embeddings[i:end_idx]\n",
    "            reduced_chunk = self.pca_reducer.transform(chunk)\n",
    "            reduced_embeddings.append(reduced_chunk)\n",
    "        \n",
    "        reduced_news = torch.cat(reduced_embeddings, dim=0)\n",
    "        # Shape is now [batch_size, 9, 10, 128, 400]\n",
    "        \n",
    "        # Step 2: Average across articles dimension\n",
    "        reduced_news = reduced_news.mean(dim=2)  # -> [batch_size, 9, 128, 400]\n",
    "        print(f\"After PCA and article averaging: {reduced_news.shape}\")\n",
    "        \n",
    "        # Step 3: Process through news_processor - applies token attention and weighted sum\n",
    "        # This takes [batch_size, 9, 128, 400] -> [batch_size, 9, 400]\n",
    "        news_features = self.news_processor(reduced_news)\n",
    "        print(f\"After weighted sum: {news_features.shape}\")\n",
    "        \n",
    "        # Step 4: Apply dimension reduction from 400 -> 128\n",
    "        # [batch_size, 9, 400] -> [batch_size, 9, 128]\n",
    "        news_features = self.tanh(self.news_dim_reducer(news_features))\n",
    "        print(f\"News features final shape: {news_features.shape}\")\n",
    "\n",
    "        # Process metrics through LSTM (previously ConvNet)\n",
    "        # metrics_data shape: [batch_size, 9, 6, 5] -> [batch_size, 9, 384]\n",
    "        metrics_features = self.lstm_net(metrics_data)\n",
    "        print(f\"Metrics features shape: {metrics_features.shape}\")\n",
    "\n",
    "        # Concatenate along feature dimension\n",
    "        combined = torch.cat([news_features, metrics_features], dim=2)  # -> [batch_size, 9, 512]\n",
    "        print(f\"Combined shape: {combined.shape}\")\n",
    "\n",
    "        # Apply linear and tanh for final embedding\n",
    "        temporal_features = self.tanh(self.concat_reducer(combined))  # -> [batch_size, 9, 312]\n",
    "        print(f\"Temporal features shape: {temporal_features.shape}\")\n",
    "\n",
    "        # Flatten and predict\n",
    "        flat_features = temporal_features.reshape(temporal_features.shape[0], -1)  # -> [batch_size, 9*312]\n",
    "        predictions = self.predictor(flat_features)  # -> [batch_size, 6*5]\n",
    "\n",
    "        return {\n",
    "            'temporal_features': temporal_features,\n",
    "            'predictions': predictions\n",
    "        }\n",
    "# === Modified process_article_folder function with memory optimization ===\n",
    "def process_article_folder(example_path, max_tokens=128, pca_reducer=None):\n",
    "    \"\"\"Process 9 days of news articles with reduced memory usage and PCA reduction\"\"\"\n",
    "    day_files = sorted([f for f in os.listdir(example_path) if f.endswith(\".txt\")])[:9]\n",
    "    daily_embeddings = []\n",
    "\n",
    "    for day_file in day_files:\n",
    "        day_path = os.path.join(example_path, day_file)\n",
    "        \n",
    "        with open(day_path, 'r', encoding='utf-8') as f:\n",
    "            articles = re.split(r'--- Article \\d+ ---', f.read())\n",
    "            articles = [a.strip() for a in articles if a.strip()]\n",
    "\n",
    "            # Ensure exactly 10 articles\n",
    "            if len(articles) > 10:\n",
    "                articles = articles[:10]\n",
    "            elif len(articles) < 10:\n",
    "                articles = articles + [''] * (10 - len(articles))\n",
    "\n",
    "        article_embeddings = []\n",
    "        \n",
    "        # Process each article\n",
    "        for article in articles:\n",
    "            if not article:\n",
    "                # For empty articles, create zero tensor of appropriate shape\n",
    "                # If using PCA, the dimensions will be reduced\n",
    "                if pca_reducer and pca_reducer.is_fitted:\n",
    "                    article_embeddings.append(torch.zeros(max_tokens, pca_reducer.output_dim).to(device))\n",
    "                else:\n",
    "                    article_embeddings.append(torch.zeros(max_tokens, 768).to(device))\n",
    "                continue\n",
    "                \n",
    "            # First tokenize to get all tokens\n",
    "            inputs = tokenizer(\n",
    "                article,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors='pt'\n",
    "            ).to(device)\n",
    "            \n",
    "            # Get non-padding token positions\n",
    "            attention_mask = inputs['attention_mask'][0]\n",
    "            valid_positions = attention_mask.nonzero().squeeze()\n",
    "            \n",
    "            # If we have fewer than max_tokens valid tokens, use all of them\n",
    "            if len(valid_positions) <= max_tokens:\n",
    "                selected_indices = valid_positions\n",
    "            else:\n",
    "                # Select tokens with regular intervals\n",
    "                step = len(valid_positions) // max_tokens\n",
    "                selected_indices = valid_positions[::step][:max_tokens]\n",
    "            \n",
    "            # Create a new inputs dictionary with only the selected tokens\n",
    "            selected_input_ids = inputs['input_ids'][0][selected_indices].unsqueeze(0)\n",
    "            selected_attention_mask = torch.ones(1, len(selected_indices)).to(device)\n",
    "            \n",
    "            selected_inputs = {\n",
    "                'input_ids': selected_input_ids,\n",
    "                'attention_mask': selected_attention_mask\n",
    "            }\n",
    "            \n",
    "            # Run through FinBERT\n",
    "            with torch.no_grad():\n",
    "                outputs = finbert_model(**selected_inputs)\n",
    "                sequence_output = outputs.last_hidden_state[0]  # [selected_tokens, 768]\n",
    "                \n",
    "                # Apply PCA reduction if provided and fitted\n",
    "                if pca_reducer and pca_reducer.is_fitted:\n",
    "                    sequence_output = pca_reducer.transform(sequence_output)\n",
    "                \n",
    "                # Pad if necessary to ensure uniform size\n",
    "                if sequence_output.shape[0] < max_tokens:\n",
    "                    # Make sure padding uses the correct dimension\n",
    "                    padding_dim = pca_reducer.output_dim if pca_reducer and pca_reducer.is_fitted else 768\n",
    "                    padding = torch.zeros(max_tokens - sequence_output.shape[0], padding_dim).to(device)\n",
    "                    sequence_output = torch.cat([sequence_output, padding], dim=0)\n",
    "                \n",
    "                article_embeddings.append(sequence_output)\n",
    "        \n",
    "        # Stack all articles for this day\n",
    "        daily_embeddings.append(torch.stack(article_embeddings))\n",
    "\n",
    "    # Stack all days\n",
    "    return torch.stack(daily_embeddings)\n",
    "\n",
    "# === Data Processing Functions ===\n",
    "def find_nearest_date(df, target_date, max_days=7):\n",
    "    \"\"\"Find closest valid date within business days.\"\"\"\n",
    "    dates = df.index\n",
    "    if target_date in dates:\n",
    "        return target_date\n",
    "\n",
    "    candidates = dates[(dates >= target_date - pd.Timedelta(days=max_days)) &\n",
    "                      (dates <= target_date + pd.Timedelta(days=max_days))]\n",
    "\n",
    "    if not candidates.empty:\n",
    "        return candidates[np.argmin(np.abs((candidates - target_date).total_seconds()))]\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_raw_metrics(df, start_date, stocks, metrics, include_target=False):\n",
    "    \"\"\"Extract 9 days of metrics data and optionally the 10th day as target\"\"\"\n",
    "    days_to_extract = 10 if include_target else 9\n",
    "    date_range = [start_date + timedelta(days=i) for i in range(days_to_extract)]\n",
    "    valid_dates = [find_nearest_date(df, d) for d in date_range]\n",
    "\n",
    "    metrics_data = []\n",
    "    for date in valid_dates[:9]:  # First 9 days are input features\n",
    "        if date is None:\n",
    "            return None, None\n",
    "\n",
    "        daily_data = []\n",
    "        for stock in stocks:\n",
    "            try:\n",
    "                stock_metrics = [df.loc[date, (metric, stock)] for metric in metrics]\n",
    "            except KeyError:\n",
    "                return None, None\n",
    "            daily_data.append(stock_metrics)\n",
    "\n",
    "        daily_tensor = torch.tensor(daily_data, dtype=torch.float32).T\n",
    "        metrics_data.append(daily_tensor)\n",
    "\n",
    "    input_tensor = torch.stack(metrics_data)  # Shape: (9, 6 metrics, 5 stocks)\n",
    "\n",
    "    # If target day is requested, extract it separately\n",
    "    target_tensor = None\n",
    "    if include_target and len(valid_dates) == 10 and valid_dates[9] is not None:\n",
    "        target_data = []\n",
    "        for stock in stocks:\n",
    "            try:\n",
    "                stock_metrics = [df.loc[valid_dates[9], (metric, stock)] for metric in metrics]\n",
    "                target_data.append(stock_metrics)\n",
    "            except KeyError:\n",
    "                return input_tensor, None\n",
    "\n",
    "        target_tensor = torch.tensor(target_data, dtype=torch.float32).flatten()\n",
    "\n",
    "    return input_tensor, target_tensor\n",
    "\n",
    "# === Generate Dataset with Memory Efficiency ===\n",
    "def generate_dataset_with_dates(df, input_dir, output_dir, split, pca_reducer=None):\n",
    "    \"\"\"Generate dataset with inputs and targets using PCA reduction\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    example_folders = sorted(os.listdir(input_dir))\n",
    "    all_news_tensors = []\n",
    "    all_metrics_tensors = []\n",
    "    all_targets = []\n",
    "    valid_examples = []\n",
    "\n",
    "    stocks = ['AAPL', 'AMZN', 'GOOGL', 'META', 'NFLX']\n",
    "    metrics = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "\n",
    "    for folder in tqdm(example_folders, desc=f\"Processing {split}\"):\n",
    "        example_path = os.path.join(input_dir, folder)\n",
    "        if not os.path.isdir(example_path):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            txt_files = sorted([f for f in os.listdir(example_path) if f.endswith(\".txt\")])\n",
    "            if len(txt_files) < 9:\n",
    "                continue\n",
    "\n",
    "            start_date_str = txt_files[0].replace(\".txt\", \"\")\n",
    "            start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
    "\n",
    "            # Process news with PCA reduction\n",
    "            news_tensor = process_article_folder(example_path, pca_reducer=pca_reducer)\n",
    "\n",
    "            # Process metrics and extract target (10th day)\n",
    "            metrics_tensor, target_tensor = extract_raw_metrics(\n",
    "                df, start_date, stocks, metrics, include_target=True\n",
    "            )\n",
    "\n",
    "            if metrics_tensor is None or target_tensor is None:\n",
    "                continue\n",
    "\n",
    "            # Collect data\n",
    "            all_news_tensors.append(news_tensor)\n",
    "            all_metrics_tensors.append(metrics_tensor)\n",
    "            all_targets.append(target_tensor)\n",
    "            valid_examples.append(folder)\n",
    "\n",
    "            # Free up memory\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed processing {folder}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # Save dataset if we have examples\n",
    "    if all_news_tensors and all_metrics_tensors and all_targets:\n",
    "        # Stack tensors in batches to save memory\n",
    "        all_news_tensors_batched = []\n",
    "        batch_size = 10  # Process in smaller batches\n",
    "        for i in range(0, len(all_news_tensors), batch_size):\n",
    "            batch = all_news_tensors[i:i+batch_size]\n",
    "            stacked_batch = torch.stack(batch)\n",
    "            all_news_tensors_batched.append(stacked_batch.cpu())\n",
    "        \n",
    "        combined_news = torch.cat(all_news_tensors_batched, dim=0)\n",
    "        combined_metrics = torch.stack(all_metrics_tensors)\n",
    "        combined_targets = torch.stack(all_targets)\n",
    "\n",
    "        # Save tensors\n",
    "        torch.save(combined_news.cpu(), os.path.join(output_dir, f\"{split}_news.pt\"))\n",
    "        torch.save(combined_metrics.cpu(), os.path.join(output_dir, f\"{split}_metrics.pt\"))\n",
    "        torch.save(combined_targets.cpu(), os.path.join(output_dir, f\"{split}_targets.pt\"))\n",
    "\n",
    "        print(f\"Saved {split} dataset with {len(valid_examples)} examples\")\n",
    "        return combined_news, combined_metrics, combined_targets\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "# === Memory-Efficient Embeddings Generation ===\n",
    "def generate_and_save_embeddings(model, news_tensors, metrics_tensors, output_dir, split, targets=None):\n",
    "    \"\"\"\n",
    "    Generate concatenated embeddings with dimension [batch×9×312] with memory efficiency\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    batch_size = news_tensors.shape[0]\n",
    "    max_batch = 4  # Smaller batch size to reduce memory usage\n",
    "\n",
    "    all_embeddings = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, batch_size, max_batch):\n",
    "            # Process a small batch at a time\n",
    "            end_idx = min(i+max_batch, batch_size)\n",
    "            print(f\"Processing batch {i} to {end_idx} of {batch_size}\")\n",
    "            \n",
    "            news_batch = news_tensors[i:end_idx].to(device)\n",
    "            metrics_batch = metrics_tensors[i:end_idx].to(device)\n",
    "\n",
    "            # Forward pass to get temporal features\n",
    "            outputs = model(news_batch, metrics_batch)\n",
    "            temporal_features = outputs['temporal_features']  # Shape: [batch, 9, 312]\n",
    "\n",
    "            all_embeddings.append(temporal_features.cpu())\n",
    "            \n",
    "            # Free up GPU memory\n",
    "            del news_batch, metrics_batch, outputs, temporal_features\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # Concatenate all batches\n",
    "    combined_embeddings = torch.cat(all_embeddings, dim=0)\n",
    "\n",
    "    # Save the embeddings\n",
    "    embedding_path = os.path.join(output_dir, f\"{split}_embeddings_9x312.pt\")\n",
    "    torch.save(combined_embeddings, embedding_path)\n",
    "\n",
    "    print(f\"Saved {split} embeddings with shape {combined_embeddings.shape} to {embedding_path}\")\n",
    "\n",
    "    return combined_embeddings\n",
    "\n",
    "# === Updated Main Function ===\n",
    "def main():\n",
    "    # Set paths\n",
    "    csv_path = \"/kaggle/input/stock-prices-full/stock_prices_complete.csv\"\n",
    "    data_dir = \"/kaggle/input/processed-data/processed_dataset_v2\"\n",
    "    output_dir = \"data/preprocessed\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Initialize PCA reducer\n",
    "    pca_reducer = PCAReducer(input_dim=768, output_dim=400)\n",
    "\n",
    "    # Load CSV with the updated format\n",
    "    print(\"Loading stock price data...\")\n",
    "    df = pd.read_csv(csv_path, header=[0, 1])\n",
    "\n",
    "    print(\"CSV structure sample:\")\n",
    "    print(df.head(3))\n",
    "\n",
    "    # Check if the first column is a date or similar indicator\n",
    "    first_col_name = df.columns[0][0]\n",
    "    first_col_subname = df.columns[0][1]\n",
    "\n",
    "    # If the first column is 'Price' or similar, use it to set the index\n",
    "    if first_col_name.lower() in ['price', 'ticker', 'date', 'time', 'datetime']:\n",
    "        # Set the index using the first column's values\n",
    "        df.index = pd.to_datetime(df.iloc[:, 0], errors='coerce')\n",
    "        # Remove the first column after setting it as index\n",
    "        df = df.iloc[:, 1:]\n",
    "        df.index.name = 'Date'\n",
    "\n",
    "    # Drop rows with NaT in index\n",
    "    df = df.loc[~pd.isna(df.index)]\n",
    "\n",
    "    # Check for business days column and filter if present\n",
    "    if ('is_business_day', '') in df.columns:\n",
    "        print(\"Filtering for business days only...\")\n",
    "        df = df[df[('is_business_day', '')] == True]\n",
    "        df = df.drop(columns=[('is_business_day', '')])\n",
    "\n",
    "    # Define the stocks and metrics based on the updated CSV structure\n",
    "    metrics = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "    stocks = ['AAPL', 'AMZN', 'GOOGL', 'META', 'NFLX']\n",
    "\n",
    "    # Check if all expected columns are present\n",
    "    for metric in metrics:\n",
    "        for stock in stocks:\n",
    "            if (metric, stock) not in df.columns:\n",
    "                print(f\"Warning: Column ({metric}, {stock}) not found in dataframe\")\n",
    "                \n",
    "                # Try to find the column with different case\n",
    "                for col_metric, col_stock in df.columns:\n",
    "                    if col_metric.lower() == metric.lower() and col_stock.lower() == stock.lower():\n",
    "                        print(f\"Found column with different case: ({col_metric}, {col_stock})\")\n",
    "                        # Rename the column to the expected case\n",
    "                        df = df.rename(columns={(col_metric, col_stock): (metric, stock)})\n",
    "                        break\n",
    "\n",
    "    # Check date range\n",
    "    print(f\"CSV date range: {df.index.min().date()} → {df.index.max().date()}\")\n",
    "    print(f\"Number of trading days: {len(df)}\")\n",
    "\n",
    "    # === Column Verification ===\n",
    "    expected_cols = [(m, s) for m in metrics for s in stocks]\n",
    "    missing_cols = [col for col in expected_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Warning: Missing {len(missing_cols)} columns out of {len(expected_cols)} expected\")\n",
    "        print(f\"First few missing columns: {missing_cols[:5]}\")\n",
    "        print(\"Available columns sample:\", df.columns[:10].tolist())\n",
    "    else:\n",
    "        print(\"✅ All required stock columns are present.\")\n",
    "\n",
    "    # Initialize model with memory-efficient architecture\n",
    "    combined_model = CombinedFinancialModel(pca_dim=400).to(device)\n",
    "    print(\"Model initialized with PCA reduction.\")\n",
    "\n",
    "    # Process all splits and generate datasets\n",
    "    all_data = {}\n",
    "    for split in [\"train\", \"val\", \"test\"]:\n",
    "        print(f\"\\nProcessing {split} split...\")\n",
    "        input_dir = os.path.join(data_dir, split)\n",
    "\n",
    "        # Check if directory exists\n",
    "        if not os.path.exists(input_dir):\n",
    "            print(f\"Warning: Directory {input_dir} does not exist. Skipping {split} split.\")\n",
    "            continue\n",
    "\n",
    "        # Generate dataset with PCA reduction\n",
    "        news_tensors, metrics_tensors, targets = generate_dataset_with_dates(\n",
    "            df, input_dir, output_dir, split, pca_reducer=pca_reducer\n",
    "        )\n",
    "\n",
    "        if news_tensors is not None:\n",
    "            # Store for later use\n",
    "            all_data[split] = {\n",
    "                'news': news_tensors,\n",
    "                'metrics': metrics_tensors,\n",
    "                'targets': targets\n",
    "            }\n",
    "\n",
    "            # Generate and save embeddings\n",
    "            print(f\"Generating embeddings for {split}...\")\n",
    "            embeddings = generate_and_save_embeddings(\n",
    "                combined_model, news_tensors, metrics_tensors, output_dir, split, targets\n",
    "            )\n",
    "            all_data[split]['embeddings'] = embeddings\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\n=== Dataset Summary ===\")\n",
    "    for split, data in all_data.items():\n",
    "        print(f\"{split.capitalize()} split:\")\n",
    "        print(f\"  • Examples: {data['news'].shape[0]}\")\n",
    "        print(f\"  • News tensor: {data['news'].shape}\")\n",
    "        print(f\"  • Metrics tensor: {data['metrics'].shape}\")\n",
    "        print(f\"  • Targets tensor: {data['targets'].shape}\")\n",
    "        print(f\"  • Embeddings tensor: {data['embeddings'].shape}\")\n",
    "\n",
    "    print(\"\\n✅ Processing complete. Generated [batch×9×312] embeddings for all splits.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7076766,
     "sourceId": 11314125,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7173335,
     "sourceId": 11449378,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
